\paragraph{abstract}
\textit{The hallmark of most artificial neural networks is their intrinsic parallelism
where each unit is evaluated concurrently to other units in a distributed way,
thus using {\em asynchronous} mechanisms.  However, this notion of asynchronous
computation is polymorphic and far from being obvious, as asserted by the
huge and somehow contradictory literature on this topic. Facing up the
related pragmatic issues, the goal of this article is twofold.  On
one hand, it precisely clarifies basic key notions related to asynchronous
distributed computations. On the other hand, a few practically usable methods
and quantitative bounds are made explicit.}

